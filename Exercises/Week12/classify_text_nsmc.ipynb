{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bba8125",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from konlpy.tag import Okt\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b6c9826",
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d36075d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    train = []\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f.readlines():\n",
    "            if count == 500:\n",
    "                break\n",
    "                \n",
    "            line = line.strip()\n",
    "            id, doc, label = line.split('\\t')\n",
    "            if label == '1': \n",
    "                label = 'pos'\n",
    "            elif label == '0': \n",
    "                label = 'neg'\n",
    "            train.append((doc, label))\n",
    "            count += 1\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "20727e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_tokenize(raw_sent):\n",
    "    pos_sent = []\n",
    "    sent = okt.pos(raw_sent, norm=True, stem=True)\n",
    "    \n",
    "    for tup in sent:\n",
    "        word, tag = tup[0], tup[1]\n",
    "        word_tag = word + '/' + tag\n",
    "        pos_sent.append(word_tag)\n",
    "    return ' '.join(pos_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f0a8be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_word_dict(train, use_morph=False):\n",
    "    all_words = set()\n",
    "    \n",
    "    for tup in train:\n",
    "        sent, label = tup[0], tup[1]\n",
    "        if use_morph:\n",
    "            sent = pos_tokenize(sent)\n",
    "        words = word_tokenize(sent)\n",
    "        for word in words:\n",
    "            all_words.add(word)\n",
    "    return all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "65433546",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_feats(train, all_words, use_morph=False):\n",
    "    train_features = []\n",
    "    \n",
    "    for tup in train:\n",
    "        sent, label = tup[0], tup[1]\n",
    "        if use_morph:\n",
    "            sent = pos_tokenize(sent)\n",
    "        words = word_tokenize(sent)\n",
    "        tmp = {set_word: (set_word in words) for set_word in all_words}\n",
    "        sent_tup = (tmp, label)\n",
    "        train_features.append(sent_tup)\n",
    "    return train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f1a4df24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('document', 'label'), ('아 더빙.. 진짜 짜증나네요 목소리', 'neg'), ('흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나', 'pos'), ('너무재밓었다그래서보는것을추천한다', 'neg'), ('교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정', 'neg'), ('사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다', 'pos'), ('막 걸음마 뗀 3세부터 초등학교 1학년생인 8살용영화.ㅋㅋㅋ...별반개도 아까움.', 'neg'), ('원작의 긴장감을 제대로 살려내지못했다.', 'neg'), ('별 반개도 아깝다 욕나온다 이응경 길용우 연기생활이몇년인지..정말 발로해도 그것보단 낫겟다 납치.감금만반복반복..이드라마는 가족도없다 연기못하는사람만모엿네', 'neg'), ('액션이 없는데도 재미 있는 몇안되는 영화', 'pos'), ('왜케 평점이 낮은건데? 꽤 볼만한데.. 헐리우드식 화려함에만 너무 길들여져 있나?', 'pos'), ('걍인피니트가짱이다.진짜짱이다♥', 'pos'), ('볼때마다 눈물나서 죽겠다90년대의 향수자극!!허진호는 감성절제멜로의 달인이다~', 'pos'), ('울면서 손들고 횡단보도 건널때 뛰쳐나올뻔 이범수 연기 드럽게못해', 'neg'), ('담백하고 깔끔해서 좋다. 신문기사로만 보다 보면 자꾸 잊어버린다. 그들도 사람이었다는 것을.', 'pos'), ('취향은 존중한다지만 진짜 내생에 극장에서 본 영화중 가장 노잼 노감동임 스토리도 어거지고 감동도 어거지', 'neg'), ('ㄱ냥 매번 긴장되고 재밋음ㅠㅠ', 'pos'), ('참 사람들 웃긴게 바스코가 이기면 락스코라고 까고바비가 이기면 아이돌이라고 깐다.그냥 까고싶어서 안달난것처럼 보인다', 'pos'), ('굿바이 레닌 표절인것은 이해하는데 왜 뒤로 갈수록 재미없어지냐', 'neg'), ('이건 정말 깨알 캐스팅과 질퍽하지않은 산뜻한 내용구성이 잘 버무러진 깨알일드!!♥', 'pos'), ('약탈자를 위한 변명, 이라. 저놈들은 착한놈들 절대 아닌걸요.', 'pos'), ('나름 심오한 뜻도 있는 듯. 그냥 학생이 선생과 놀아나는 영화는 절대 아님', 'pos'), ('보면서 웃지 않는 건 불가능하다', 'pos'), ('재미없다 지루하고. 같은 음식 영화인데도 바베트의 만찬하고 넘 차이남....바베트의 만찬은 이야기도 있고 음식 보는재미도 있는데 ; 이건 볼게없다 음식도 별로 안나오고, 핀란드 풍경이라도 구경할랫는데 그것도 별로 안나옴 ㅡㅡ', 'neg'), ('절대 평범한 영화가 아닌 수작이라는걸 말씀드립니다.', 'pos'), ('주제는 좋은데 중반부터 지루하다', 'neg'), ('다 짤랐을꺼야. 그래서 납득할 수 없었던거야.. 그럴꺼야.. 꼭 그랬던걸꺼야..', 'neg'), ('kl2g 고추를 털어버려야 할텐데', 'pos'), ('카밀라벨 발연기', 'neg'), ('재밋는뎅', 'pos'), ('센스있는 연출력..탁월한 캐스팅..90년대의 향수.. 그래서 9점..', 'pos'), ('엄포스의 위력을 다시 한번 깨닫게 해준 적.남 꽃검사님도 연기 정말 좋았어요! 완전 명품드라마!', 'pos'), ('졸쓰레기 진부하고말도안됌ㅋㅋ 아..시간아까워', 'neg'), ('재밌는데 별점이 왜이리 낮은고', 'pos'), ('1%라도 기대했던 내가 죄인입니다 죄인입니다....', 'neg'), ('아직도 이 드라마는 내인생의 최고!', 'pos'), ('패션에 대한 열정! 안나 윈투어!', 'pos'), ('키이라 나이틀리가 연기하고자 했던건 대체 정신장애일까 틱장애일까', 'neg'), ('허허...원작가 정신나간 유령이라... 재미있겠네요!', 'pos'), ('포스터는 있어보이는데 관객은 114명이네', 'neg'), ('이 영화가 왜 이렇게 저평가 받는지 모르겠다', 'pos'), ('단순하면서 은은한 매력의 영화', 'pos'), (\"'다 알바생인가 내용도 없고 무서운거도 없고 웃긴거도 하나도 없음 완전 별싱거운 영화.ㅇ.ㅇ내ㅇ시간 넘 아까움 .. . 완전 낚임\", 'neg'), ('오게두어라! 서리한이 굶주렸다!', 'pos'), ('정말 맘에 들어요. 그래서 또 보고싶은데 또 보는 방법이 없네? >.. ㅜㅡ', 'pos'), ('윤제문이라는 멋진 배우를 발견하게 됐어요. 소소한 일탈이 잔잔한 미소를 머금게 합니다. 음악은 조금 아쉽네요ㅠㅠ 8점 주고 싶은데 평점 올리고 싶어 10점 줄게요^^', 'pos'), ('평점에속지마시길시간낭비 돈낭비임', 'neg'), ('리얼리티가 뛰어나긴 한데 큰 공감은 안간다. 이민기캐릭터는 정신의학상 분노조절장애 초기 증상일거다. 툭하면 사람패고 욕하고 물건 파손하고.. 조금 오바였음. 극 초반엔 신선했는데 가면 갈수록 이민기 정신상태 공감불가.', 'neg'), ('마이너스는 왜없냐 ㅋ 뮤비 보고 영화수준 딱 알만하더군 ㅉㅉ 북한에서 이런거 만들라고 돈 대주던?', 'neg'), ('난 우리영화를 사랑합니다....^^;', 'neg'), ('데너리스 타르 가르엔...나도 용의주인이 되고 싶다...누이랑,근친상간이나 하고 다닐지라도,소설 속에선 제일 멋진 놈이 자이메 라니스터였는데,드라마속에선,드래곤(용)이 제일 멋지네(웃음)감독님 토르-2 다크 월드는 말아 잡수셨을지라도,기본 선방은 했음', 'pos'), ('영화가 사람의 영혼을 어루만져 줄 수도 있군요 거친 세상사를 잠시 잊고 동화같은 영화에 행복했네요', 'pos'), ('야 세르게이! 작은고추의 매운맛을 보여주마! 포퐁저그 콩진호가 간다', 'neg'), ('이렇게 가슴시리게 본 드라마가 또 있을까? 감동 그 자체!', 'pos'), ('난또 저 꼬마애가 무슨 원한이 깊길래.,. 했더니 OO 그냥 혼자 나대다 OO걸 어쩌라고.', 'neg'), ('재미있어요', 'pos'), ('전 좋아요', 'pos'), ('최고', 'neg'), ('너무 충격적이엇다. 기분을 완전히 푹 꺼지게 하는 느낌... 활력이라고는 하나도 없는 너무나도 무거운....지독하고 차갑고 무자비하다. 그저 일본인들의 상상력은 정말 대단한거 같다는 생각이 든다.', 'pos'), ('심심한영화.', 'neg'), ('백봉기 언제나오나요?', 'pos'), ('보는내내 그대로 들어맞는 예측 카리스마 없는 악역', 'neg'), ('불알이 나와서 당황...아무튼 영화가 중간에 끝나는 느낌', 'neg'), ('평범함속에 녹아든 평범한 일상. 조금 밋밋한게 흠.', 'neg'), ('보던거라 계속보고있는데 전개도 느리고 주인공인 은희는 한두컷 나오면서 소극적인모습에 짜증이 ㅜㅜ 맨날 언제끝나나 기대만하고있어요 전개좀 빨리빨리 ㅜㅜ', 'neg'), ('사랑하고싶게하는,가슴속온감정을헤집어놓는영화예요정말최고.', 'pos'), ('많은 사람들이 이 다큐를 보고 우리나라 슬픈 현대사의 한 단면에 대해 깊이 생각하고 사죄하고 바로 잡기 위해 노력했으면 합니다. 말로만 듣던 보도연맹, 그 민간인 학살이 이정도 일 줄이야. 이건 명백한 살인입니다. 살인자들은 다 어디있나요?', 'pos'), ('예전 작품 캐릭터, 에피소드 재탕 삼탕 사골우려먹듯 우리고 내용은 산으로 가고 시청률은 아예안나오고 이제 70회중반인데 120부작이라니 ...', 'neg'), ('김남길의 백점짜리 연기력과 초반 몰입도에도 불구하고 지루하고 손예진 ㅈㅈ', 'neg'), ('재밌네 비슷한 영화를 안보신 분들한테는 재미있을 듯', 'pos'), ('노래실력으로뽑는게 맞냐? 박시환이 mama나가면 진짜 망신이다', 'neg'), ('아 일본영화 다이런건가?? 유치하다', 'neg'), ('이틀만에 다 봤어요 재밌어요 근데 차 안에 물건 넣어 조작하려고 하면 차 안이 열려있다던지 집 안이 활짝 열려서 아무나 들어간다던가 문자를 조작하려고하면 비번이 안 걸려있고 ㅋㅋㅋ 그런 건 억지스러웠는데 그래도 내용 자체는 좋았어요', 'pos'), ('졸작', 'neg'), ('재밋네요 달팽이가 빨라서 더 재밌었어요', 'pos'), ('어설픈 전개 어이없는 결말', 'neg'), ('부패한 로마노프 왕조를 기리는 뭣같은 영화... 온몸으로 항거했던 러시아 민중들이 그저 폭도냐', 'neg'), ('내용전개는 무난한 편이였구 잘 보았습니다 ^^', 'pos'), ('매우 실망.....', 'neg'), ('한국영화 흥행코드: 갈등-갈등-계~에속 갈등-화해-감동- 평점 10점 남발- 흥행 뻔하지 뭐...', 'neg'), ('아햏햏 아햏햏 아햏햏.', 'pos'), ('뭐냐..시작하고 3분만에 나왔다. 리플릿 사진 보며 불안하더니만..', 'neg'), ('단연 최고라고 할수있지', 'pos'), ('감독이 럼먹고 영화를 만들었나보다.. 관객에게 뭘 말하는지도 모르겠고, 엉망진창 개진창이다.', 'neg'), ('이건 뭐냐? 우뢰매냐? ;;;', 'neg'), ('정말쓰레기영화입니다', 'neg'), ('진정 위대한 영화 최고임', 'pos'), ('별루 였다..', 'neg'), ('내일이 기대되는 `', 'pos'), ('근데 조미가 막문위 좋아한건가요??', 'pos'), ('ㅋㅋㅋ 진짜 골깜..ㅋㅋ 눈 부라릴때 쓰러짐..ㅋㅋ', 'pos'), ('성룡영화중 최악인듯 ㅋㅋ', 'neg'), ('골때리네ㅋㅋㅋㅋ 걸스데이 이혜리 잘 되라!', 'pos'), ('서기가이뻐서', 'pos'), ('완전 재밌어요ㅋㅋㅋㅋㅋ백인공주귀여움ㅋㅋㅋㅋㅋㅋ', 'pos'), ('인상적인 영화였다', 'pos'), ('어내스트와 셀레스틴 완전 강추에요~ 정말 재밌습니다^^', 'pos'), ('재미있는영화입니다.', 'pos'), ('클라라볼라고화신본거아닌데', 'neg'), ('진짜 보면서 너무 슬펐던 영화다', 'pos')]\n"
     ]
    }
   ],
   "source": [
    "train = load_data('ratings_train.txt')\n",
    "print(train[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bbd377a",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_morph = True\n",
    "all_words = make_word_dict(train, use_morph)\n",
    "train_feature = make_train_feats(train, all_words, use_morph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c01e27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ab6ac44",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = urllib.request.urlretrieve(\n",
    "    \"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\",\n",
    "    filename=\"ratings_test.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ab3bcad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                       ; = True              neg : pos    =      8.2 : 1.0\n",
      "          재미없다/Adjective = True              neg : pos    =      8.2 : 1.0\n",
      "                주인공/Noun = True              neg : pos    =      7.5 : 1.0\n",
      "                 최고/Noun = True              pos : neg    =      6.9 : 1.0\n",
      "                  뭐/Noun = True              neg : pos    =      6.8 : 1.0\n",
      "           재밌다/Adjective = True              pos : neg    =      6.5 : 1.0\n",
      "                 내용/Noun = True              neg : pos    =      6.2 : 1.0\n",
      "       ㅡㅡ/KoreanParticle = True              neg : pos    =      6.1 : 1.0\n",
      "                스토리/Noun = True              neg : pos    =      6.1 : 1.0\n",
      "                 다시/Noun = True              pos : neg    =      5.9 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_feature)\n",
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "17bc33c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg\n",
      "neg\n",
      "neg\n",
      "pos\n",
      "pos\n",
      "neg\n",
      "neg\n",
      "pos\n",
      "pos\n",
      "pos\n",
      "pos\n",
      "pos\n",
      "pos\n",
      "neg\n",
      "pos\n",
      "neg\n",
      "pos\n",
      "neg\n",
      "neg\n",
      "pos\n",
      "pos\n",
      "pos\n",
      "neg\n",
      "neg\n",
      "pos\n",
      "pos\n",
      "neg\n",
      "pos\n",
      "pos\n",
      "pos\n",
      "neg\n",
      "neg\n",
      "neg\n",
      "neg\n",
      "neg\n",
      "pos\n",
      "neg\n",
      "pos\n",
      "neg\n",
      "neg\n",
      "neg\n",
      "pos\n",
      "neg\n",
      "pos\n",
      "pos\n",
      "neg\n",
      "pos\n",
      "pos\n",
      "neg\n",
      "pos\n",
      "neg\n",
      "neg\n",
      "pos\n",
      "pos\n",
      "neg\n",
      "neg\n",
      "pos\n",
      "pos\n",
      "pos\n",
      "neg\n",
      "pos\n",
      "pos\n",
      "pos\n",
      "neg\n",
      "pos\n",
      "pos\n",
      "pos\n",
      "pos\n",
      "neg\n",
      "pos\n",
      "neg\n",
      "neg\n",
      "pos\n",
      "pos\n",
      "pos\n",
      "pos\n",
      "neg\n",
      "neg\n",
      "neg\n",
      "pos\n",
      "pos\n",
      "pos\n",
      "pos\n",
      "pos\n",
      "pos\n",
      "pos\n",
      "pos\n",
      "neg\n",
      "neg\n",
      "neg\n",
      "pos\n",
      "pos\n",
      "neg\n",
      "neg\n",
      "neg\n",
      "pos\n",
      "neg\n"
     ]
    }
   ],
   "source": [
    "# test_sent = '재미없다'\n",
    "# print(test_sent)\n",
    "# test_sent = pos_tokenize(test_sent)\n",
    "# print(test_sent)\n",
    "# words = word_tokenize(test_sent)\n",
    "# test_feature = {set_word: (set_word in words) for set_word in all_words}\n",
    "\n",
    "sents = load_data('ratings_test.txt')\n",
    "for i in range(3, 100):\n",
    "    test_sent = sents[i][0]\n",
    "    test_sent = pos_tokenize(test_sent)\n",
    "    words = word_tokenize(test_sent)\n",
    "    test_feature = {set_word: (set_word in words) for set_word in all_words}\n",
    "    print(classifier.classify(test_feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30024558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neg'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "classifier.classify(test_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbd7552",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
